---
title: 'Projekt zaliczeniowy: IloÅ›ciowe miary ryzyka rynkowego 25/26'
author: "Aleksandra Konopelska"
output: 
  html_document:
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

library(tidyverse)  # pakiet do przetwarzania danych i wizualizacja (ggplot2, dplyr)
library(moments)    # pakiet do obliczania skoÅ›noÅ›ci i kurtozy
library(tseries)    # pakiet do testÃ³w statystycznych (np. Jarque-Bera)
library(knitr)      # pakiet do tabel
library(gridExtra)  # pakiet do wykresu
library(tseries)    # pakiet do testÃ³w normalnoÅ›ci
library(nortest)    # pakiet do testu normalnoÅ›ci Andersona-Darlinga
library(knitr)      # pakiet do tabeli w var i es
library(rugarch)    # pakiet do testÃ³w VaR
```


# Wprowadzenie do projektu

## Cel i zakres projektu

Celem mojego projektu bÄ™dzie analiza ryzyka rynkowego dla wybranego przeze mnie indeksu **WIG20** na podstawie danych dziennych z lat 2016â€“ 2024 (speÅ‚niajÄ…cych wymÃ³g min. 8 lat).

W projekcie bÄ™dÄ™ realizowaÅ‚a nastÄ™pujÄ…ce zadania:

1.  **Opisanie empirycznego rozkÅ‚adu stÃ³p zwrotu**: wyÅ›wietle statystyki opisowe oraz skomentujÄ™ kluczowe wyniki.
2.  **Sprawdzenie za pomocÄ… min. dwÃ³ch testÃ³w normalnoÅ›ci**, czy dane dzienne speÅ‚niajÄ… zaÅ‚oÅ¼enie o normalnoÅ›ci.
3.  **Zbudowanie szeregu oszacowaÅ„ 99% VaR i 99% ES** w oparciu o 500-dniowe okno historyczne, wykorzystujÄ…c dwie wybrane wersje metody historycznej:
    * Prosta metoda historyczna
    * Metoda historyczna z wagami
4.  **OdpowiedÅº na pytanie, czy wyznaczony VaR jest wyznaczony wiarygodnie** (tj. nie jest zawyÅ¼ony ani zaniÅ¼ony) w oparciu o moje wyniki testÃ³w wstecznych (dla dÅ‚ugoÅ›ci $m=250$).
5.  **Ocena koÅ„cowa**, czy moje wyniki pozwalajÄ… twierdziÄ‡, Å¼e obie metody dajÄ… wiarygodne oszacowania.

## O indeksie WIG20

**WIG20** â€“ indeks gieÅ‚dowy 20 najwiÄ™kszych spÃ³Å‚ek akcyjnych notowanych na warszawskiej GieÅ‚dzie PapierÃ³w WartoÅ›ciowych. BazowÄ… datÄ… dla indeksu jest 16 kwietnia 1994, zaÅ› wartoÅ›ciÄ… bazowÄ… 1000 punktÃ³w.

**Kluczowe cechy indeksu:**

* **Typ indeksu:** Jest to indeks typu cenowego (przy jego obliczaniu bierze siÄ™ pod uwagÄ™ jedynie ceny zawartych w nim transakcji).
* **Ograniczenia:** W ramach WIG20 nie moÅ¼e byÄ‡ notowanych wiÄ™cej niÅ¼ 5 spÃ³Å‚ek z jednego sektora gieÅ‚dowego.
* **Wykluczenia:** W skÅ‚adzie indeksu nie sÄ… notowane fundusze inwestycyjne.

Å¹rÃ³dÅ‚o: *Wikipedia (pl.wikipedia.org/wiki/WIG20)*

## Pakiety

Pakiety, ktÃ³re wykorzystujÄ™ w projekcie:

```{r}
library(tidyverse)  # pakiet do przetwarzania danych i wizualizacja (ggplot2, dplyr)
library(moments)    # pakiet do obliczania skoÅ›noÅ›ci i kurtozy
library(tseries)    # pakiet do testÃ³w statystycznych (np. Jarque-Bera)
library(knitr)      # pakiet do tabel
library(gridExtra)  # pakiet do wykresu
library(tseries)    # pakiet do testÃ³w normalnoÅ›ci
library(nortest)    # pakiet do testu normalnoÅ›ci Andersona-Darlinga
library(knitr)      # pakiet do tabeli w var i es
library(rugarch)    # pakiet do testÃ³w VaR
```

## Zmienne

Moja analiza bÄ™dzie przeprowadzona w oparciu o wybrany przeze mnie plik **`wig20_d.csv`** zawierajÄ…cy notowania indeksu WIG20. Szereg czasowy obejmuje dane dzienne.

Zbioru danych posiada zmienne:

| Nazwa zmiennej | Typ danych | Opis |
| :--- | :---: | :--- | :--- |
| **Data** | Data (YYYY-MM-DD) | DzieÅ„ sesji gieÅ‚dowej. | 
| **Otwarcie** | Liczbowy (Float) | Kurs indeksu na otwarciu sesji. | 
| **Najwyzszy** | Liczbowy (Float) | Maksymalna wartoÅ›Ä‡ indeksu w trakcie sesji. | 
| **Najnizszy** | Liczbowy (Float) | Minimalna wartoÅ›Ä‡ indeksu w trakcie sesji. | 
| **Zamkniecie** | Liczbowy (Float) | Kurs indeksu na zamkniÄ™ciu sesji. | 
| **Wolumen** | Liczbowy (Integer) | WartoÅ›Ä‡ obrotu akcjami wchodzÄ…cymi w skÅ‚ad indeksu. | 


# Przygotowanie danych

## WybÃ³r i filtracja danych

Do analizy ryzyka wybraÅ‚am indeks **WIG20** (plik `wig20_d.csv`). Dane obejmujÄ… okres od **2007-01-02** do **2024-11-29**, ale zgodnie z zaÅ‚oÅ¼eniami min. 8 lat, wybraÅ‚am okres od **2016-01-01** do **2024-11-29** co stanowi blisko 9 lat. Taki zakres pozwoli mi przetestowaÄ‡ model w czasie kryzysÃ³w i konfliktÃ³w na Å›wiecie, jak pandemia COVID-19 czy wojna na Ukrainie.

W strukturze danych uwzglÄ™dniÅ‚am wymogi instrukcji:

1.  **500-dniowe okno historyczne:** pierwsze 500 obserwacji, ktÃ³re posÅ‚uÅ¼Ä… jako baza do wyliczenia pierwszych miar ryzyka.

2.  **Okres dla testÃ³w wstecznych (m=250):** ostatnie 250 obserwacji, na ktÃ³rych sprawdzÄ™ wiarygodnoÅ›Ä‡ wyznaczonych prognoz VaR.

```{r}
# wczytuje wybrane przeze mnie dane
df <- read.csv("wig20_d.csv", stringsAsFactors = FALSE)
df$Data <- as.Date(df$Data) # ustawiam dane jako typ data

df <- df %>% 
  # ukÅ‚adam dni po kolei (od najstarszego), bo stopÄ™ zwrotu liczy siÄ™: (cena z dzisiaj / cena z wczoraj)
  # i dni nie mogÄ… byÄ‡ pomieszane bo wyjdÄ… zÅ‚e wyniki
  arrange(Data) %>% 
  
  # wybieram dane od 1 stycznia 2016 do koÅ„ca mojego pliku
  # dziÄ™ki temu mam okres badawczy prawie 9 lat
  filter(Data >= "2016-01-01") %>%
  
  # wybieram dane potrzebne mi do wzoru na stopy zwrotu  
  # Zi = ln(Si / Si-1)
  # Si -> cena zamkniÄ™cia (Zamkniecie) w dniu i
  # Si-1 -> cena z dnia poprzedniego
  select(Data, Zamkniecie)

# tworzÄ™ tabele dla sprawdzenia moich danych
weryfikacja <- data.frame(
  Start_Badania = min(df$Data),
  Koniec_Badania = max(df$Data),
  Liczba_Dni = nrow(df),
  Wymagane_Minimum = 750 
  # wymagane min. danych by mÃ³jprojekt miaÅ‚ sens
  # "500 dni okna" + "250 dni testÃ³w" = 750, tyle muszÄ™ mieÄ‡ min.
)

# tabela
kable(weryfikacja, caption = "Podsumowanie zakresu danych")
```




# Metodyka wyznaczania stÃ³p zwrotu

Instytucja finansowa powinna monitorowaÄ‡ zmiennoÅ›Ä‡ cen rynkowych dla interesujÄ…cych jÄ… walorÃ³w (m.in. stÃ³p procentowych, cen akcji, kursÃ³w walutowych itp.). Na zajÄ™ciach definiowaliÅ›my proste i logarytmiczne stopy zwrotu:

1.  **Proste stopy zwrotu**:
    $$Z_i = \frac{S_i - S_{i-1}}{S_{i-1}}$$

2.  **Logarytmiczne stopy zwrotu**:
    $$Z_i = \ln\left(\frac{S_i}{S_{i-1}}\right)$$

gdzie we wzorach:

* $Z_i$ â€“ stopa zwrotu w dniu $i$.

* $S_i$ â€“ wartoÅ›Ä‡ zmiennej (cena zamkniÄ™cia) w dniu $i$.

* $S_{i-1}$ â€“ wartoÅ›Ä‡ zmiennej w dniu poprzednim.


**MÃ³j wybÃ³r:**

W moim projekcie zdecydowaÅ‚am siÄ™ na wykorzystanie **logarytmicznych stÃ³p zwrotu**. 

Oba podejÅ›cia majÄ… zalety i wady, ale o ile znajomoÅ›Ä‡ stÃ³p prostych w bardziej naturalny sposÃ³b oddaje informacjÄ™ o tym, jak zmienia siÄ™ cena danego waloru, to lepsze wÅ‚asnoÅ›ci matematyczne majÄ… stopy logarytmiczne. W stopach logarytmicznych Å‚Ä…czny zwrot z caÅ‚ego okresu (na przykÅ‚ad tygodnia) jest po prostu sumÄ… zwrotÃ³w dziennych. Przy stopach prostych musiaÅ‚abym stosowaÄ‡ bardziej skomplikowane mnoÅ¼enie, co utrudniaÅ‚oby obliczenia na duÅ¼ym zbiorze danych (jak u mnie okno 500 dni).


```{r}
# obliczam log stopy zwrotu (Zi)
# funkcja (-) diff(log()): ln(Si) - ln(Si-1)
# wynik mnoÅ¼Ä™ * 100, aby mieÄ‡ procenty (np. 1.5%), a nie uÅ‚amki (0.015)
# aby uÅ‚atwiÄ‡ interpretacjÄ™ wykresÃ³w
df$LogReturn <- c(NA, diff(log(df$Zamkniecie)) * 100)

# usuwam pierwszy wiersz
# wczeÅ›niej uÅ¼yÅ‚am funkcji 'filter', ktÃ³ra wyrzuciÅ‚a stare dane sprzed mojego wybranego okresu min. 8 lat
# przez to dla 1 stycznia 2016 nie widaÄ‡ dnia wczorajszego 
# powstaje bÅ‚Ä…d (NA) i dlatego muszÄ™ go usunÄ…Ä‡ 
df <- na.omit(df)

# wyniki
kable(head(df), 
      col.names = c("Data (i)", "Cena ZamkniÄ™cia (Si)", "Log Stopa Zwrotu (Zi) [%]"),
      caption = "Wyznaczone stopy zwrotu dla indeksu WIG20")
```


## Wykresy zmiennoÅ›ci

PoniÅ¼sze wykresy przedstawiajÄ… przebieg notowaÅ„ wybranego przeze mnie indeksu WIG20 oraz jego dzienne stopy zwrotu. Jest to wstÄ™pny etap analizy ryzyka, pozwalajÄ…cy oceniÄ‡ charakter rynku.

```{r}
p1 <- ggplot(df, aes(x = Data, y = Zamkniecie)) +
  geom_line(color = "darkblue", size = 0.6) +
  labs(
    title = "Notowania indeksu WIG20 (Ceny)", 
    y = "Cena zamkniÄ™cia [pkt]",  
    # WIG20 jest indeksem gieÅ‚dowym wiÄ™c jego wartoÅ›Ä‡ podaje siÄ™ w punktach, a nie w zÅ‚
    # punkty te odzwierciedlajÄ… Å‚Ä…cznÄ… wartoÅ›Ä‡ rynkowÄ… 20 najwiÄ™kszych spÃ³Å‚ek
    x = "Data"
  ) +
   theme_minimal() +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") + # by pokazaÄ‡ rok po roku na osi Y
  theme(axis.text.x = element_text(angle = 45, hjust = 1))   # by lekko pochyliÄ‡ daty Å¼eby siÄ™ zmieÅ›ciÅ‚y

p1
```

**Wnioski z wykresu Notowania indeksu WIG20:**

Na wykresie widaÄ‡ zmiany ceny zamkniÄ™cia indeksu WIG20 na przeÅ‚omie moich wybranych lat **2016-01-01** do **2024-11-29**:

1.  WidaÄ‡ na nim wyraÅºne **trendy**: rynek nie stoi w miejscu, tylko falami roÅ›nie i spada.
2.  WidaÄ‡ reakcje na wydarzenia na Å›wiecie: najbardziej gwaÅ‚towny pionowy spadek wystÄ…piÅ‚ w marcu 2020 roku przez wybuch pandemii i pÃ³Åºniej w 2022-2023 zwiÄ…zane z wojnÄ… na Ukrainie.

Jest to obraz **cen ($S_i$)**, ktÃ³re posÅ‚uÅ¼Ä… mi w kolejnym kroku do obliczenia stÃ³p zwrotu.

```{r}
p2 <- ggplot(df, aes(x = Data, y = LogReturn)) +
  geom_line(color = "darkred", size = 0.4) +
  labs(title = "Logarytmiczne stopy zwrotu WIG20", y = "Logarytmiczna stopa zwrotu/dzienna zmiana ceny na gieÅ‚dzie [%]", x = "Data") +
  theme_minimal()

p2
```

**Wnioski z wykresu Logarytmiczne stopy zwrotu:**

* **ZmiennoÅ›Ä‡ nie jest staÅ‚a:** na powyÅ¼szym wykresie widaÄ‡ wyraÅºne rÃ³Å¼nice w "nerwowoÅ›ci" rynku w rÃ³Å¼nych latach. Czyli jest koniecznoÅ›Ä‡ monitorowania zmiennoÅ›ci cen rynkowych (ryzyko na gieÅ‚dzie nie jest staÅ‚e, raz panuje spokÃ³j, raz duÅ¼a nerwowoÅ›Ä‡, wiÄ™c musimy na bieÅ¼Ä…co sprawdzaÄ‡ aktualnÄ… sytuacjÄ™, aby dobrze oceniÄ‡ zagroÅ¼enie).

* **ZmiennoÅ›Ä‡ w klastrach/grupach (heteroskedastycznoÅ›Ä‡):** moÅ¼na takÅ¼e zauwaÅ¼yÄ‡ na powyÅ¼szym wykresie, Å¼e znaczne spadki i wzrosty cen czÄ™sto wystÄ™pujÄ… w seriach/grupach po sobie. Jest to szczegÃ³lnie widoczne w okresach szokÃ³w na rynku, takich jak na poczÄ…tku 2020 roku (Pandemia COVID-19) czy poczÄ…tek 2022 roku (wybuch wojny na Ukrainie).

* **WystÄ™powanie wartoÅ›ci ekstremalnych (grube ogony):** analiza powyÅ¼szego wykresu sugeruje teÅ¼, Å¼e dzienne stopy zwrotu nie majÄ… rozkÅ‚adu normalnego. WidaÄ‡ to poprzez bardzo dÅ‚ugie linie na wykresie (np. gwaÅ‚towny spadek na poczÄ…tku 2020 roku), te obserwacje wskazujÄ… na wyÅ¼sze prawdopodobieÅ„stwo wystÄ…pienia krachÃ³w/spadkÃ³w, niÅ¼ zakÅ‚adaÅ‚by to rozkÅ‚ad normalny.

Moje powyÅ¼sze obserwacje sugerujÄ… odrzucenie hipotezy o normalnoÅ›ci rozkÅ‚adu, co w kolejnym kroku zweryfikujÄ™ testami statystycznymi.


# Analiza statystyczna rozkÅ‚adu stÃ³p zwrotu

WstÄ™pna analiza wykresÃ³w w poprzedniej czÄ™Å›ci projektu zasugerowaÅ‚a mi, Å¼e **stopy zwrotu mojego indeksu WIG20 charakteryzujÄ… siÄ™ duÅ¼Ä… zmiennoÅ›ciÄ… i wystÄ™powaniem wartoÅ›ci skrajnych** (bardzo dÅ‚ugie linie na wykresie/widoczne gwaÅ‚towne spadki, np. spadek na poczÄ…tku 2020 roku). W tej czÄ™Å›ci projektu zweryfikujÄ™ te obserwacje metodami statystycznymi.

**Celem tego etapu jest sprawdzenie, czy dzienne stopy zwrotu (czyli % zmiany cen z dnia na dzieÅ„) moÅ¼na opisaÄ‡ rozkÅ‚adem normalnym.** Wynik tej analizy posÅ‚uÅ¼y jako gÅ‚Ã³wne uzasadnienie dla wyboru metodyki (czyli konkretnego sposobu obliczania ryzyka VaR) w mojej dalszej czÄ™Å›ci pracy.

Weryfikacja ta jest niezbÄ™dna, poniewaÅ¼ planujÄ™ wykorzystaÄ‡ **Metody Historyczne ProstÄ… i z Wagami**. ZaletÄ… metody historycznej jest to Å¼e cechujÄ… jÄ… proste obliczenia oraz, brak zaÅ‚oÅ¼eÅ„ matematycznych dot. rozkÅ‚adu stÃ³p zwrotu (tj. zaÅ‚oÅ¼enie o normalnoÅ›ci). Pozwali to na bezpoÅ›rednie wykorzystanie danych historycznych i uwzglÄ™dnienie "grubych ogonÃ³w" oraz gwaÅ‚townych krachÃ³w, ktÃ³re rozkÅ‚ad normalny czÄ™sto ignoruje.

Metoda prosta zakÅ‚ada, Å¼e szanse na realizacjÄ™ kaÅ¼dego scenariusza sÄ… takie same. Aby uniknÄ…Ä‡ tego, wprowadze MetodÄ™ HistorycznÄ… z Wagami. WybÃ³r metody z wagami wynika z faktu, Å¼e nowe obserwacje powinny mieÄ‡ wiÄ™kszÄ… wagÄ™, gdyÅ¼ lepiej odzwierciedlajÄ… aktualnÄ… zmiennoÅ›Ä‡ oraz obecne warunki na rynku. PrzyjmujÄ…c, Å¼e prawdopodobieÅ„stwa piâ€‹ malejÄ… wykÅ‚adniczo (nadaje rÃ³Å¼nÄ… waÅ¼noÅ›Ä‡ danym w zaleÅ¼noÅ›ci od tego, jak dawno wystÄ…piÅ‚y; najnowsze dni majÄ… najwiÄ™kszy wpÅ‚yw na wynik VaR, a wpÅ‚yw starszych dni maleje bardzo szybko wraz z upÅ‚ywem czasu), model moÅ¼e szybciej "zapominaÄ‡" o odlegÅ‚ej przeszÅ‚oÅ›ci i bardziej dynamicznie reagowaÄ‡ na nowe szoki rynkowe.

Dlatego, jeÅ›li poniÅ¼sze testy wykaÅ¼Ä… brak normalnoÅ›ci (czyli obecnoÅ›Ä‡ nagÅ‚ych spadkÃ³w cen w moich danych), bÄ™dzie to potwierdzeniem, Å¼e powinnam zastosowaÄ‡ **Metody Historyczne** (w wersji prostej oraz z wagami). 


## Statystyki opisowe

```{r}
# obliczenie statystyk opisowych
statystyki <- data.frame(
  Miara = c("Åšrednia", "Odchylenie Std.", "Mediana", "Kwartyl 1 (25%)", "Kwartyl 3 (75%)", "SkoÅ›noÅ›Ä‡", "Kurtoza", "Min", "Max"),
  Wartosc = c(
    mean(df$LogReturn),
    sd(df$LogReturn),
    median(df$LogReturn),            
    quantile(df$LogReturn, 0.25),    
    quantile(df$LogReturn, 0.75),    
    skewness(df$LogReturn),
    kurtosis(df$LogReturn),
    min(df$LogReturn),
    max(df$LogReturn)
  )
)

# tabela
kable(statystyki, digits = 4, caption = "Statystyki opisowe logarytmicznych stÃ³p zwrotu WIG20")
```

**Interpretacja wynikÃ³w powyÅ¼szej tabeli Statystyki opisowe logarytmicznych stÃ³p zwrotu WIG20:**

 - **Kurtoza:** wynosi 11.6612 jest to bardzo wysoki wynik. Åšwiadczy to o wystÄ™powaniu "grubych ogonÃ³w". Oznacza to, Å¼e krachy/spadki w WIG20 zdarzajÄ… siÄ™ w rzeczywistoÅ›ci znacznie czÄ™Å›ciej, niÅ¼ wynikaÅ‚oby to z zaÅ‚oÅ¼eÅ„ rozkÅ‚adu normalnego.

 - **SkoÅ›noÅ›Ä‡:** wynik ujemny (-0.6682) oznacza, Å¼e na rynku czÄ™Å›ciej wystÄ™powaÅ‚y gwaÅ‚towne spadki niÅ¼ gwaÅ‚towne wzrosty.

 - **Minimum:** najwiÄ™ksza dzienna strata wyniosÅ‚a aÅ¼ -14.24%, co potwierdza wystÄ™powanie krachÃ³w rynkowych w badanym okresie.

**Wniosek:** Tak wysoka kurtoza i wystÄ™powanie strat okoÅ‚o -14% potwierdzajÄ… mi, Å¼e rozkÅ‚ad stÃ³p zwrotu nie jest normalny. 


## Wizualizacja normalnoÅ›ci

### Histogram

```{r}
moja_srednia <- mean(df$LogReturn)
moje_odchylenie_std <- sd(df$LogReturn)

ggplot(df, aes(x = LogReturn)) +  

  # after_stat(density) = zamiast liczby dni pokazujemy gÄ™stoÅ›Ä‡,
  # Å¼eby histogram byÅ‚ w tej samej skali co rozkÅ‚ad normalny
  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = "grey", color = "white", alpha = 0.7) +
  stat_function(fun = dnorm, 
                args = list(mean = moja_srednia, sd = moje_odchylenie_std), 
                color = "red", size = 1) +
  labs(title = "Histogram stÃ³p zwrotu WIG20 vs rozkÅ‚ad normalny",
       x = "Dzienna stopa zwrotu [%]", 
       y = "GÄ™stoÅ›Ä‡") +
  theme_minimal()
```

Na histogramie widaÄ‡ przede wszystkim leptokurtyczny charakter rozkÅ‚adu (wysoki szczyt, wÄ…ska koncentracja wokÃ³Å‚ Å›redniej, kurtoza u mnie to 11.66). ObecnoÅ›Ä‡ "grubych ogonÃ³w" jest lepiej widoczna na poniÅ¼szym wykresie Q-Q, gdzie punkty na kraÅ„cach wyraÅºnie odbiegajÄ… od linii referencyjnej rozkÅ‚adu normalnego

### Wykres Q-Q

Wykresy Q-Q (Quantile-Quantile) to narzÄ™dzie pozwalajÄ…ce porÃ³wnaÄ‡ dane z rozkÅ‚adem normalnym. Na wykresie Q-Q rzeczywiste dane sÄ… przedstawione na osi X, a teoretyczne kwantyle rozkÅ‚adu normalnego na osi Y. JeÅ›li punkty na wykresie Q-Q zbliÅ¼ajÄ… siÄ™ do prostej linii, oznacza to, Å¼e dane sÄ… zbliÅ¼one do rozkÅ‚adu normalnego.

Å¹rÃ³dÅ‚o: *[statystykabiomed.pl](https://statystykabiomed.pl/2024/03/28/1-8-jak-ocenic-normalnosc-rozkladu/).*

Wykres dla moich danych: 

```{r}
# wykres Q-Q dla stÃ³p zwrotu
qqnorm(df$LogReturn, 
       main = "Wykres Q-Q dla stÃ³p zwrotu WIG20", 
       xlab = "Teoretyczne kwantyle (RozkÅ‚ad Normalny)", 
       ylab = "Rzeczywiste stopy zwrotu (WIG20)",
       col = "blue", pch = 19, cex = 0.5) 
# pch -> wypeÅ‚nienie pkt., cex -> wielkoÅ›Ä‡ pkt.

# dodaje czerwonÄ… linie do odniesienia (idealny rozkÅ‚ad normalny)
qqline(df$LogReturn, col = "red", lwd = 2) # lwd -> gruboÅ›Ä‡ linii do odniesienia
```

**Interpretacja powyÅ¼szego wykresu Q-Q:**

PowyÅ¼szy wykres dobrze pokazuje dowodÃ³w na brak normalnoÅ›ci rozkÅ‚adu stÃ³p zwrotu WIG20.

 - Punkty odchylajÄ… siÄ™ na obu koÅ„cach od linii referencyjnej. (JeÅ›li punkty na wykresie Q-Q zbliÅ¼ajÄ… siÄ™ do prostej linii, oznacza to, Å¼e dane sÄ… zbliÅ¼one do rozkÅ‚adu normalnego.)

 - Lewy ogon: w lewym dolnym rogu niebieskie punkty znaczÄ…co odchodzÄ… w dÃ³Å‚ od czerwonej linii. Oznacza to, Å¼e w rzeczywistoÅ›ci na rynku wystÄ™pujÄ… znacznie gÅ‚Ä™bsze spadki, niÅ¼ wynikaÅ‚oby to z zaÅ‚oÅ¼eÅ„ rozkÅ‚adu normalnego.


**Wniosek:** Wykres moÅ¼e potwierdziÄ‡ Å¼e istniejÄ… "grube ogony". Zastosowanie w tym przypadku metod parametrycznych (zakÅ‚adajÄ…cych normalnoÅ›Ä‡) prowadziÅ‚oby do drastycznego zaniÅ¼enia ryzyka i zignorowania najwiÄ™kszych krachÃ³w. 


## Testy normalnoÅ›ci rozkÅ‚adu

Zgodnie z wymogami instrukcji ("za pomocÄ… min. dwÃ³ch testÃ³w"), aby ostatecznie potwierdziÄ‡, Å¼e stopy zwrotu nie podlegajÄ… rozkÅ‚adowi normalnemu, przeprowadzam trzy testy statystyczne (metody statystyczne weryfikujÄ…ce, czy dane pochodzÄ… z populacji o rozkÅ‚adzie normalnym):

- **Test Jarque-Bera:** kluczowy test w mojej analizie, poniewaÅ¼ bezpoÅ›rednio weryfikuje skoÅ›noÅ›Ä‡ i kurtozÄ™, ktÃ³re obliczyÅ‚am powyÅ¼ej. Test ten porÃ³wnuje moje dane do idealnego rozkÅ‚adu normalnego/Gaussa (dla ktÃ³rego skoÅ›noÅ›Ä‡ wynosi 0, a kurtoza 3). Sprawdza on, czy skoÅ›noÅ›Ä‡ i kurtoza moich danych rÃ³Å¼niÄ… siÄ™ istotnie od tych wartoÅ›ci oczekiwanych. Im bardziej moje dane odbiegajÄ… od normy (np. przez wystÄ™powanie "grubych ogonÃ³w"), tym wynik statystyki JB bÄ™dzie wyÅ¼szy.

 - **Test Shapiro-Wilka:** to podstawowy test statystyczny sÅ‚uÅ¼Ä…cy do weryfikacji, czy rozkÅ‚ad prÃ³by badawczej jest zbliÅ¼ony do rozkÅ‚adu normalnego. Test ten ma najwyÅ¼szÄ… moc dla maÅ‚ych i Å›rednich prÃ³b (zalecany do N<5000), czyli pasujÄ…cy do moich danych WIG20. Przy bardzo duÅ¼ych prÃ³bach moÅ¼e byÄ‡ zbyt czuÅ‚y, jednak w poÅ‚Ä…czeniu z testem JB stanowi solidne potwierdzenie wynikÃ³w.

 - **Test Andersona-Darlinga:** to kolejny test statystyczny ktÃ³rego uÅ¼yje sÅ‚uÅ¼Ä…cy do sprawdzenia, czy dane majÄ… rozkÅ‚ad normalny. WybraÅ‚am go, poniewaÅ¼ jest on bardziej czuÅ‚y na odchylenia w obszarach brzegowych (w ogonach), co w przypadku danych o czÄ™stym wystÄ™powaniu wartoÅ›ci skrajnych (tzw. grubych ogonÃ³w), jak w moich logarytmicznych stopach zwrotu WIG20, daje bardziej wiarygodne podstawy do odrzucenia zaÅ‚oÅ¼enia o normalnoÅ›ci.
 
**Hipotezy badawcze dla wybranych przeze mnie testÃ³w:**

* **$H_0$:** RozkÅ‚ad stÃ³p zwrotu jest normalny ($p \ge 0.05$).
* **$H_1$:** RozkÅ‚ad stÃ³p zwrotu nie jest normalny ($p < 0.05$).

**Decyzja:** JeÅ›li wartoÅ›Ä‡ **p-value** jest niska (mniejsza od przyjÄ™tego poziomu istotnoÅ›ci $\alpha = 0.05$), odrzucÄ™ $H_0$ i stwierdzÄ™ brak normalnoÅ›ci.

```{r}
# 1. test Jarque-Bera
test_jb <- jarque.bera.test(df$LogReturn)

# 2. test Shapiro-Wilka
test_sw <- shapiro.test(df$LogReturn)

# 3. test Andersona-Darlinga
test_ad <- ad.test(df$LogReturn)

# zestawienie wynikÃ³w testÃ³w w tabeli
wyniki_testow <- data.frame(
  Test = c("Jarque-Bera", "Shapiro-Wilk", "Anderson-Darling"),
  Statystyka = c(as.numeric(test_jb$statistic), 
                 as.numeric(test_sw$statistic), 
                 as.numeric(test_ad$statistic)),
  p_value = c(
    format(test_jb$p.value, scientific = FALSE),
    format(test_sw$p.value, scientific = FALSE), # uÅ¼ywam funkcji format() aby pokazaÄ‡ peÅ‚nÄ… liczbÄ™ p-value zamiast skrÃ³tu naukowego
    format(test_ad$p.value, scientific = FALSE)
  )
)

# tabela
kable(wyniki_testow, digits = 4, caption = "Wyniki trzech testÃ³w normalnoÅ›ci dla stÃ³p zwrotu WIG20")
```

**Interpretacja powyÅ¼szych wynikÃ³w:**

 - **Statystyka Jarque-Bera (7136.21):** p-value â‰ˆ 0. MÃ³j wynik jest bardzo wysoki, co wynika z wczeÅ›niejszych obliczeÅ„: ogromnej kurtozy (11.66) i ujemnej skoÅ›noÅ›ci (na rynku czÄ™Å›ciej wystÄ™powaÅ‚y gwaÅ‚towne spadki niÅ¼ gwaÅ‚towne wzrosty). To dowÃ³d na to, Å¼e rozkÅ‚ad stÃ³p zwrotu WIG20 jest bardzo daleki od normalnego.

 - **Test Shapiro-Wilka (0.9469):** p-value â‰ˆ 0 i wynik statystyki potwierdzajÄ… wynik pierwszego testu. 

 - **Test Andersona-Darlinga:** p-value â‰ˆ 0 stanowi trzecie, potwierdzenie braku normalnoÅ›ci. 
  
 - **p-value â‰ˆ 0:** we wszystkich trzech przeprowadzonych testach (JB, SW, AD) wartoÅ›ci te sÄ… â‰ˆ 0 (poniÅ¼ej poziomu istotnoÅ›ci 0.05).

**Wniosek:** Na podstawie wynikÃ³w trzech wybranych testÃ³w statystycznych jednoznacznie odrzucam hipotezÄ™ o normalnoÅ›ci rozkÅ‚adu ($H_0$). Te same wyniki we wszystkich testach potwierdzajÄ…, Å¼e rozkÅ‚ad stÃ³p zwrotu WIG20 posiada "grube ogony", co oznacza, Å¼e ryzyko wystÄ…pienia duÅ¼ych strat jest w rzeczywistoÅ›ci znacznie wyÅ¼sze, niÅ¼ zakÅ‚adaÅ‚by rozkÅ‚ad normalny. Stanowi to moje ostateczne uzasadnienie dla wyboru **Metody Symulacji Historycznej** (w obu wariantach: prostym i z wagami).


# Wyznaczanie VaR i ES

## Uzasadnienie wyboru metod

1.  **WybÃ³r Prosta Metody Historycznej:** metoda ta opiera siÄ™ na zaÅ‚oÅ¼eniu Å¼e "jutrzejszy wynik naszej inwestycji powtÃ³rzy jeden z historycznych rezultatÃ³w". W tym podejÅ›ciu kaÅ¼dy dzieÅ„ z przeszÅ‚oÅ›ci (np. jak u mnie z 500 dni) ma takÄ… samÄ… szansÄ™ ponownego wystÄ…pienia (p=1/N). WybraÅ‚am jÄ… poniewaÅ¼ buduje ona rozkÅ‚ad ryzyka bezpoÅ›rednio w oparciu o konkretne wyniki, ktÃ³re faktycznie wystÄ…piÅ‚y w przeszÅ‚oÅ›ci. DziÄ™ki temu model "pamiÄ™ta" rzeczywiste krachy/spadki (takie jak wybuch pandemii czy wojny na Ukrainie) i uwzglÄ™dnia je w prognozie.

2. **WybÃ³r Metody Historycznej z Wagami:** w tej metodzie zmieniam podejÅ›cie, stosujÄ…c zasadÄ™ Å¼e "im starszy scenariusz, tym mniejsze prawdopodobieÅ„stwo realizacjiâ€. W Etapie 1 zauwaÅ¼yÅ‚am na wykresie zmiennoÅ›Ä‡ w czasie (okresy spokoju i nagÅ‚ej nerwowoÅ›ci). Prosta metoda reagowaÅ‚aby na te zmiany zbyt wolno (traktujÄ…c dalszy rok 2016 tak samo jak wczoraj). Wersja z wagami naprawia ten problem nadajÄ…c wiÄ™ksze znaczenie nowszym obserwacjom w danych, lepiej oddaje bieÅ¼Ä…ce warunki na rynku. Wagi malejÄ… wykÅ‚adniczo w czasie. ZastosujÄ™ parametr zaniku q=0.99 (w kodzie programu zmienna jako lambda) sprawi Å¼e najnowsze dane majÄ… wiÄ™kszy wpÅ‚yw na wynik VaR, co pozwala modelowi szybciej adaptowaÄ‡ siÄ™ do bieÅ¼Ä…cych warunkÃ³w rynkowych.

**WzÃ³r na wagi:** 

$$
p_i = \frac{q^{n-i}(1-q)}{1-q^n}
$$

Gdzie u mnie:

* $n = 500$ (liczba dni w oknie),
* $q = 0.99$ (mÃ³j parametr zaniku, dziÄ™ki niemu mogÄ™ "manipulowaÄ‡ szybkoÅ›ciÄ… "zapominaniaâ€ (czyli decydujemy o tym, jak szybko prawdopodobieÅ„stwa zdarzeÅ„ starszych malejÄ…), ğ‘ âˆˆ 0,1 z reguÅ‚y jest bardzo bliskie 1 (np. 0.995)

## Implementacja modelu (Szereg oszacowaÅ„ VaR i ES)

W tej czÄ™Å›ci projektu realizujÄ™ punkt instrukcji: "w oparciu o 500-dniowe okno historyczne, zbudowaÄ‡ szereg oszacowaÅ„ 99% VaR i 99% ES".

Aby zbudowaÄ‡ wymagany szereg oszacowaÅ„ (a nie tylko jednÄ… wartoÅ›Ä‡), obliczenia bÄ™dÄ™ wykonywaÅ‚a za pomocÄ… pÄ™tli dla kaÅ¼dego dnia badanego okresu. **BÄ™dzie to dziaÅ‚aÅ‚o nastÄ™pujÄ…co:**

 - Dla kaÅ¼dego badanego dnia, pobieram z historii dokÅ‚adnie 500 ostatnich stÃ³p zwrotu, ktÃ³re poprzedzajÄ… ten dzieÅ„.

 - Na podstawie tych 500 obserwacji wyliczam bieÅ¼Ä…cÄ… wartoÅ›Ä‡ ryzyka (VaR i ES) i zapisujÄ™ wynik dla danego dnia.

 - PrzechodzÄ™ do kolejnego dnia i powtarzam proces. DziÄ™ki temu, Å¼e za kaÅ¼dym razem biorÄ™ aktualne 500 dni wstecz, mÃ³j model na bieÅ¼Ä…co uwzglÄ™dnia nowe informacje pÅ‚ynÄ…ce z rynku, a stare dane naturalnie wychodzÄ… poza zakres analizy.


**Obliczenia wykonam dwiema wybranymi przeze mnie metodami:**

1. **Prosta Metoda Historyczna:** gdzie bÄ™dÄ™ traktowaÄ‡ wszystkie 500 dni w oknie historycznym jednakowo (wagi rÃ³wne).

2. **Metoda Historyczna z Wagami:** w tym podejÅ›ciu bÄ™dÄ™ przypisywaÄ‡ obserwacjom wagi, ktÃ³re malejÄ… w czasie (parametr Î»=0.99). DziÄ™ki temu najnowsze dane w 500-dniowym oknie majÄ… znacznie wiÄ™kszy wpÅ‚yw na wynik (wyÅ¼szÄ… wagÄ™) niÅ¼ dane starsze. Pozwoli to modelowi szybciej adaptowaÄ‡ siÄ™ do bieÅ¼Ä…cych warunkÃ³w na rynku.
    
```{r}
# konfiguruje mÃ³j model
dlugosc_okna <- 500      # dÅ‚ugoÅ›Ä‡ okna (N=500), tyle dni wstecz biorÄ™ do analizy
poziom_istotnosci <- 0.01
lambda <- 0.99           #  parametr 'q' dla metody z wagami (na slajdach z reguÅ‚y bardzo bliskie 1) dziÄ™ki niemu nowsze dane sÄ… waÅ¼niejsze dla modelu


# przygotowuje miejsca na wyniki
liczba_wszystkich_dni <- nrow(df)  # sprawdzam ile mam wierszy w danych (df)

# tworzÄ™ puste pojemniki/miejsca (wektory), wypeÅ‚nione na razie brakami danych (NA)
# by mieÄ‡ zarezerwowane miejsce, zanim zacznÄ™ liczyÄ‡ w pÄ™tli

# miejsce na wyniki Prostej Metody Historycznej
wyniki_proste_var <- rep(NA, liczba_wszystkich_dni)
wyniki_proste_es  <- rep(NA, liczba_wszystkich_dni)

# miejsce na wyniki Metody z wagami 
wyniki_wagi_var <- rep(NA, liczba_wszystkich_dni)
wyniki_wagi_es  <- rep(NA, liczba_wszystkich_dni)
```


WewnÄ…trz pÄ™tli, dla kaÅ¼dego 500-dniowego okna, wyznaczam ryzyko dwiema wybranymi przeze mnie metodami:

1. **Prosta Metoda Historyczna**

* *VaR 99%*: sortujÄ™ 500 historycznych stÃ³p zwrotu od najgorszej do najlepszej. Skoro szukam 1% najgorszych przypadkÃ³w z 500 dni, wyznaczam VaR jako wartoÅ›Ä‡ piÄ…tego wyniku na tej liÅ›cie ($500 \times 0,01 = 5$). Jest to moja "bezpieczna granica", zakÅ‚adam, Å¼e z 99% pewnoÅ›ciÄ… rzeczywista strata nie bÄ™dzie wiÄ™ksza niÅ¼ ta liczba.

* *ES 99%*: to wartoÅ›Ä‡ oczekiwana strat przekraczajÄ…cych poziom VaR. W moim kodzie, dla danych dyskretnych (skoÅ„czona prÃ³ba 500 dni), estymujÄ™ to jako Å›redniÄ… z obserwacji w ogonie rozkÅ‚adu (czyli Å›redniÄ… z 5 najgorszych wynikÃ³w). Wynik ten informuje mnie o tym, jak duÅ¼a bÄ™dzie przeciÄ™tna strata, jeÅ›li moja bezpieczna granica (VaR) zostanie przekroczona.

2. **Metoda Historyczna z Wagami**

W tej metodzie nie traktujÄ™ wszystkich dni jednakowo. PrzyjmujÄ™ zaÅ‚oÅ¼enie, Å¼e dni z ostatniego tygodnia sÄ… dla modelu waÅ¼niejsze (majÄ… wiÄ™kszy wpÅ‚yw na wynik) niÅ¼ z dalszego okresu czasu.

* *VaR 99%*: ukÅ‚adam listÄ™ dni od najwiÄ™kszej straty do najwiÄ™kszego zysku. KaÅ¼dy dzieÅ„ ma swojÄ… "wagÄ™" (waÅ¼noÅ›Ä‡). SumujÄ™ wagi tych dni, zaczynajÄ…c od najwiÄ™kszych strat. W momencie, gdy suma waÅ¼noÅ›ci osiÄ…gnie poziom 1%, sprawdzam, jaki wynik przypisany byÅ‚ do ostatniego dodanego dnia â€“> jest bÄ™dzie mÃ³j VaR.

* *ES 99%*: wyznaczam to jako Å›redniÄ… waÅ¼onÄ… z najgorszych wynikÃ³w. W odrÃ³Å¼nieniu od metody prostej, tutaj nowsze krachy majÄ… wiÄ™kszy wpÅ‚yw na ostateczny wynik. JeÅ›li duÅ¼a strata zdarzyÅ‚a siÄ™ niedawno, mÃ³j ES bÄ™dzie znacznie wyÅ¼szy, poniewaÅ¼ model uznaje to zdarzenie za bardziej istotne dla bieÅ¼Ä…cej oceny ryzyka.
 

**Uwaga do Metody z wagami:** W tej metodzie nie stosujÄ™ zwykÅ‚ej Å›redniej arytmetycznej, poniewaÅ¼ byÅ‚oby to bÅ‚Ä™dne przy danych, ktÃ³re majÄ… rÃ³Å¼ne wagi. Zamiast tego bÄ™dÄ™ obliczaÄ‡ Å›redniÄ… waÅ¼onÄ… z ogona rozkÅ‚adu. Polega to na wyodrÄ™bnieniu 1% najgorszych wynikÃ³w i przeliczeniu ich wag tak, aby wewnÄ…trz samego ogona sumowaÅ‚y siÄ™ do 1 (normalizacja). DziÄ™ki temu wynik metody jest spÃ³jny z modelem VaR i sprawia, Å¼e niedawne, gwaÅ‚towne spadki majÄ… wiÄ™kszy wpÅ‚yw na prognozowanÄ… wielkoÅ›Ä‡ ekstremalnej straty.
    
```{r}
# moja pÄ™tla obliczeniowa
# zaczynam pracÄ™ od wiersza 501 (czyli od 3 stycznia 2018 roku), 
# bo dopiero wtedy mam w moim oknie historycznym peÅ‚ne 500 dni historii z lat 2016-2017
for(i in (dlugosc_okna + 1):liczba_wszystkich_dni) {
  
  # wybieram z tabeli 500 ostatnich dni, Å¼eby na ich podstawie sprawdziÄ‡, 
  # jakie ryzyko mamy dzisiaj (w dniu o numerze i)
  historia <- df$LogReturn[(i - dlugosc_okna):(i - 1)]

# metoda 1: Prosta Metoda Historyczna
  
  # ukÅ‚adam te 500 wynikÃ³w w kolejce: od najwiÄ™kszej straty do najwiÄ™kszego zysku
  historia_posortowana <- sort(historia)
  
  # szukam 1% najgorszych przypadkÃ³w z 500 dni (bo 1% z 500 to 5)
  indeks_var <- ceiling(poziom_istotnosci * dlugosc_okna) # ceiling -> zaokrÄ…gla wynik zawsze w gÃ³rÄ™ do peÅ‚nej liczby
  
  # ta piÄ…ta najgorsza wartoÅ›Ä‡ to mÃ³j VaR "z 99% pewnoÅ›ciÄ… dzisiaj nie stracÄ™ wiÄ™cej niÅ¼ to"
  wyniki_proste_var[i] <- historia_posortowana[indeks_var]
  
 # obliczam Å›rednia z 1% najgorszych wynikÃ³w
 # bÄ™dzie mi ona mÃ³wiÄ‡ jakiej Å›redniej straty mogÄ™ siÄ™ spodziewaÄ‡, jeÅ›li sytuacja na gieÅ‚dzie 
 # pogorszy siÄ™ bardziej niÅ¼ przewiduje to poziom VaR.
 wyniki_proste_es[i] <- mean(historia_posortowana[1:indeks_var])
  
  
# metoda 2: Metoda Historyczna z Wagami
  
  # przypisuje wagi
  # generujÄ™ potÄ™gi od 499 do 0; dziÄ™ki temu najnowszy dzieÅ„ (potÄ™ga 0) 
  # dostanie najwiÄ™kszÄ… wagÄ™ (lambda^0 = 1), a najstarszy najmniejszÄ…
  potegi <- (dlugosc_okna - 1):0 
  wagi_surowe <- lambda ^ potegi
  
  # dzielÄ™ wagi przez ich sumÄ™, aby Å‚Ä…cznie dawaÅ‚y 1 (suma wszystkich prawdopodobieÅ„stw musi wynosiÄ‡ dokÅ‚adnie 1 (100%))
  # aby traktowaÄ‡ je jako prawdopodobieÅ„stwa w rozkÅ‚adzie
  wagi <- wagi_surowe / sum(wagi_surowe) 
  
  # tworzÄ™ tabelÄ™, w ktÃ³rej kaÅ¼demu wynikowi z historii
  # przypisujÄ™ jego wyliczonÄ… wage ("waÅ¼noÅ›Ä‡")
  tabela_pomocnicza <- data.frame(zwrot = historia, waga = wagi)
  
  # ukÅ‚adam wyniki w kolejnoÅ›ci od najgorszego (najwiÄ™ksza strata) do najlepszego
  tabela_pomocnicza <- tabela_pomocnicza[order(tabela_pomocnicza$zwrot), ]
  
  # wyznaczam VaR
  # liczÄ™ sumÄ™ skumulowanÄ… wag idÄ…c od najgorszych strat
  tabela_pomocnicza$waga_skumulowana <- cumsum(tabela_pomocnicza$waga)
  
  # szukam momentu, w ktÃ³rym skumulowana waga przekroczy mÃ³j prÃ³g 1% (0.01)
  # pierwszy wynik speÅ‚niajÄ…cy ten warunek to bÄ™dzie mÃ³j VaR
  indeks_wagi <- which(tabela_pomocnicza$waga_skumulowana >= poziom_istotnosci)[1]
  wyniki_wagi_var[i] <- tabela_pomocnicza$zwrot[indeks_wagi]
  
  # ES to Å›rednia strata z najgorszych dni ktÃ³re przebiÅ‚y barierÄ™ VaR
  # dlatego biorÄ™ z tabeli tylko wiersze od poczÄ…tku (najwiÄ™ksza strata) 
  # aÅ¼ do momentu gdzie znajduje siÄ™ mÃ³j VaR -> resztÄ™ odrzucam
  dane_ogon <- tabela_pomocnicza[1:indeks_wagi, ]
  
  # poniewaÅ¼ wyciÄ™Å‚am tylko fragment danych (ogon), sumuje siÄ™ on do maÅ‚ej liczby
  # przeliczam ich wagi tak, aby w tej grupie sumowaÅ‚y siÄ™ do 100% (1.0)
  # gdybym tego nie podzieliÅ‚a, Å›rednia strata wyszÅ‚aby bÅ‚Ä™dna (za maÅ‚a)
  wagi_ogon_norm <- dane_ogon$waga / sum(dane_ogon$waga)

  # liczÄ™ Å›redniÄ… waÅ¼onÄ… strat w ogonie
  # dziÄ™ki temu niedawne ekstremalne straty mocniej wpÅ‚ywajÄ… na wynik ES
  wyniki_wagi_es[i] <- sum(dane_ogon$zwrot * wagi_ogon_norm)
}


# przenosze moje wyniki:
# do tej pory wyliczone ryzyko (VaR i ES) trzymaÅ‚am w osobnych, tymczasowych listach
# teraz wklejam te listy do mojej gÅ‚Ã³wnej tabeli z danymi (df) jako nowe kolumny
# dziÄ™ki temu obok daty i zwrotu bÄ™dÄ™ miaÅ‚a od razu wyliczone ryzyko dla kaÅ¼dego dnia
df$VaR_Prosta_99 <- wyniki_proste_var
df$ES_Prosta_99  <- wyniki_proste_es
df$VaR_Wagi_99 <- wyniki_wagi_var
df$ES_Wagi_99  <- wyniki_wagi_es

# poniewaÅ¼ moja pÄ™tla zaczÄ™Å‚a liczyÄ‡ wyniki dopiero od 501. dnia (styczeÅ„ 2018)
# pierwsze 500 wierszy w kolumnach VaR i ES jest pustych (NA)
# usuwam je aby zostawiÄ‡ tylko te dni, dla ktÃ³rych mam peÅ‚ne wyniki modelu
df_model <- na.omit(df)

# podglÄ…d wynikÃ³w dla sprawdzenia poprawnoÅ›ci
kable(head(df_model[, c("Data", "LogReturn", "VaR_Prosta_99", "ES_Prosta_99", "VaR_Wagi_99", "ES_Wagi_99")]), 
      caption = "Pierwsze oszacowania ryzyka (VaR i ES)")
```

**Wnioski z tabeli kilku poczÄ…tkowych danych:**

 - **VaR vs ES:** ES generuje wyÅ¼szÄ… stratÄ™ niÅ¼ VaR (ok. -3,21% vs -2,67%). Czyli, na poczÄ…tkowych kilku danych mogÄ™ powiedzieÄ‡ Å¼e model dziaÅ‚a dobrze na razie bo VaR wyznacza maksymalnÄ… tolerowanÄ… stratÄ™ na danym poziomie ufnoÅ›ci, natomiast ES szacuje Å›redniÄ… wielkoÅ›Ä‡ straty w sytuacji, gdy ten poziom zostanie przekroczony.

 - **Prosta Metoda Historyczna:** wyznaczyÅ‚a u mnie wyÅ¼szy poziom ryzyka (ok. -2,67%), poniewaÅ¼ wciÄ…Å¼ uwzglÄ™dnia dawne krachy z historii z takÄ… samÄ… waÅ¼noÅ›ciÄ… jak dni obecne.

 - **Metoda Historyczna z Wagami**: pokazaÅ‚a niÅ¼sze ryzyko (ok. -2,01%), poniewaÅ¼ szybciej zareagowaÅ‚a na ostatni spokÃ³j na gieÅ‚dzie, nadajÄ…c nowszym danym wiÄ™ksze znaczenie.


**RÃ³Å¼nica w metodach:** Dla kilku poczÄ…tkowych zmiennych mogÄ™ jak na razie stwierdziÄ‡, Å¼e metoda Prosta ocenia ryzyko surowiej (-2,67%), poniewaÅ¼ pamiÄ™ta stare krachy z przeszÅ‚oÅ›ci. Metoda WaÅ¼ona jest bardziej optymistyczna (-2,01%), bo zauwaÅ¼a, Å¼e ostatnio na rynku panuje spokÃ³j i szybko obniÅ¼a wymogi kapitaÅ‚owe.


## Wizualizacja wynikÃ³w

**Prosta Metoda Historyczna:**
```{r}
ggplot(df_model, aes(x = Data)) +
  geom_line(aes(y = LogReturn), color = "gray80", alpha = 0.5) +
  geom_line(aes(y = VaR_Prosta_99, color = "VaR 99%"), size = 0.8) +
  geom_line(aes(y = ES_Prosta_99, color = "ES 99%"), size = 0.8, linetype = "dashed") +
  scale_color_manual(values = c("VaR 99%" = "red", "ES 99%" = "blue")) +
  labs(title = "Metoda Prosta: VaR, ES",
       y = "Stopa zwrotu / Ryzyko [%]", x = "Data", color = "Miara ryzyka") +
  theme_minimal() + theme(legend.position = "bottom")
```

Linie na wykresie sÄ… doÅ›Ä‡ sztywne. Dzieje siÄ™ tak, poniewaÅ¼ Metoda Prosta wolno reaguje na nowe dane i dÅ‚ugo "pamiÄ™ta" stare wydarzenia. Linia przerywana (ES) znajduje siÄ™ zawsze poniÅ¼ej linii ciÄ…gÅ‚ej (VaR): Å›rednia strata z najgorszych dni jest bardziej dotkliwa niÅ¼ sam prÃ³g, od ktÃ³rego te najgorsze dni zaczynamy liczyÄ‡. 


**Metoda Historyczna z Wagami**:
```{r}
ggplot(df_model, aes(x = Data)) +
  geom_line(aes(y = LogReturn), color = "gray80", alpha = 0.5) +
  geom_line(aes(y = VaR_Wagi_99, color = "VaR 99%"), size = 0.8) +
  geom_line(aes(y = ES_Wagi_99, color = "ES 99%"), size = 0.8, linetype = "dashed") +
  scale_color_manual(values = c("VaR 99%" = "red", "ES 99%" = "blue")) +
  labs(title = "Metoda z Wagami: VaR, ES",
       y = "Stopa zwrotu / Ryzyko [%]", x = "Data", color = "Miara ryzyka") +
  theme_minimal() + theme(legend.position = "bottom")
```

WidaÄ‡, Å¼e linie na tym wykresie sÄ… bardziej poszarpane. Oznacza to, Å¼e model jest bardzo czuÅ‚y: szybciej reaguje na zmiany cen, podnoszÄ…c lub obniÅ¼ajÄ…c ryzyko z dnia na dzieÅ„. Podobnie jak w poprzednim wykresie, przerywana linia (ES) biegnie poniÅ¼ej ciÄ…gÅ‚ej (VaR). Potwierdza to, Å¼e model poprawnie liczy Å›redniÄ… stratÄ™, ktÃ³ra jest zawsze dotkliwsza niÅ¼ "prÃ³g ostrzegawczy." 


**PorÃ³wnanie Metod:**
```{r}
ggplot(df_model, aes(x = Data)) +
  # rzeczywiste wyniki z gieÅ‚dy (zyski i straty)
  geom_bar(aes(y = LogReturn), stat = "identity", fill = "lightgray", alpha=0.5) +
  
  # metoda prosta
  geom_line(aes(y = VaR_Prosta_99, color = "VaR Prosty"), size = 0.8) +
  geom_line(aes(y = ES_Prosta_99, color = "ES Prosty"), size = 0.8, linetype = "dashed") +
  
  # metoda z wagami
  geom_line(aes(y = VaR_Wagi_99, color = "VaR z Wagami"), size = 0.8) +
  geom_line(aes(y = ES_Wagi_99, color = "ES z Wagami"), size = 0.8, linetype = "dashed") +
  
  
  scale_color_manual(values = c("VaR Prosty" = "red", 
                                "ES Prosty" = "darkred",
                                "VaR z Wagami" = "blue", 
                                "ES z Wagami" = "darkblue")) +
  
  labs(title = "Zestawienie razem: VaR i ES (Prosta vs z Wagami)",
       y = "Stopa zwrotu / Ryzyko [%]", 
       x = "Data", 
       color = "Legenda") +
  
  theme_minimal() + 
  theme(legend.position = "bottom")
```

Na powyÅ¼szym wykresie widaÄ‡ Å¼e VaR z metody z wagami (linia niebieska) jest bardziej zmienny i szybciej reaguje na nagÅ‚e wzrosty ryzyka, co jest szczegÃ³lnie widoczne w okresach kryzÃ³w na Å›wiecie, takich jak pandemia COVID-19 czy poczÄ…tek wojny na Ukrainie. Prosta metoda historyczna (linia czerwona) reaguje wolniej i daje bardziej wygÅ‚adzony, stabilny poziom ryzyka, poniewaÅ¼ w rÃ³wnym stopniu uwzglÄ™dnia takÅ¼e stare obserwacje. W okresach stabilizacji rynku VaR z metody z wagami szybciej siÄ™ obniÅ¼a, lepiej odzwierciedlajÄ…c bieÅ¼Ä…ce warunki rynkowe.



# Weryfikacja modeli (Backtesting)

Zgodnie z wymogami projektu (dla dÅ‚ugoÅ›ci m = 250), w tej czÄ™Å›ci bÄ™dÄ™ dokonywaÄ‡ walidacji moich modeli na prÃ³bie testowej obejmujÄ…cej **ostatnie 250 dni sesyjnych**. Moim celem bÄ™dzie odpowiedzenie na pytanie, czy wyznaczony VaR jest wyznaczony wiarygodnie (tj. nie jest zawyÅ¼ony ani zaniÅ¼ony). Czy owe wyniki pozwalajÄ… twierdziÄ‡, Å¼e obie metody dajÄ… wiarygodne oszacowania?


WeryfikacjÄ™ opieram na trzech rzeczach:

1.  **Analiza iloÅ›ciowa wyjÄ…tkÃ³w (tzw. test wartoÅ›ci rzeczywistych.):** 

sprawdzam, czy liczba dni, w ktÃ³rych ponieÅ›liÅ›my stratÄ™ wiÄ™kszÄ… niÅ¼ VaR, jest bliska 1%.

 - jeÅ›li wyjÄ…tkÃ³w jest za duÅ¼o, to znaczy, Å¼e model jest zbyt optymistyczny i zaniÅ¼a ryzyko (naraÅ¼a na niespodziewane straty).

 - jeÅ›li wyjÄ…tkÃ³w jest za maÅ‚o (np. 1 na 600 dni, jak w przykÅ‚adzie z wykÅ‚adu), to model jest zbyt ostroÅ¼ny. To teÅ¼ jest bÅ‚Ä…d, bo na przykÅ‚ad zmusza bank do niepotrzebnego zamraÅ¼ania gotÃ³wki w rezerwach, zamiast niÄ… obracaÄ‡.
 

2.  **Testy statystyczne:**

**Test Kupca:** to test statystyczny ktÃ³rego statystyka opiera siÄ™ na logarytmie wiarogodnoÅ›ci i ma rozkÅ‚ad $\chi^2(1)$. Jego hipotezy to
 
 * $H_0$: VaR jest dobrze wyznaczony.
 * $H_1$: VaR nie jest dobrze wyznaczony.

**Test Christoffersona:** test ktÃ³ry odpowiada na pytanie, czy momenty przekroczenia VaR (wyjÄ…tki) sÄ… od siebie niezaleÅ¼ne, czy teÅ¼ wystÄ™pujÄ… seriami (klastrowanie). WystÄ…pienie jednego wyjÄ…tku nie jest jeszcze tak zÅ‚e, ale jeÅ›li pociÄ…ga on za sobÄ… kolejne przekroczenia w nastÄ™pnych dniach, moÅ¼e to oznaczaÄ‡ "poczÄ…tek cyklu zÅ‚ych zdarzeÅ„". Jego hipotezy to:
 
 * $H_0$: przekroczenia VaR sÄ… niezaleÅ¼ne w czasie.
 * $H_1$: przekroczenia VaR nie sÄ… niezaleÅ¼ne w czasie.
    
3. **PodejÅ›cie regulacyjne dla testowania wstecznego**: 

to test/regulator, ktÃ³ry wprowadziÅ‚ kolorowe strefy (tzw. test
Å›wiateÅ‚), ktÃ³re mÃ³wiÄ… o tym, jak groÅºne sÄ… zaobserwowane przekroczenia VaR

 - **Strefa Zielona (0-4 wyjÄ…tki)**: jest to sytuacja bezpieczna, bo regulator uznaje model za wiarygodny. 

 - **Strefa Å»Ã³Å‚ta (5-9 wyjÄ…tkÃ³w)**: to strefa ktÃ³ra mÃ³wi Å¼e model myli siÄ™ zbyt czÄ™sto. Oznacza sytuacjÄ™, w ktÃ³rej trzeba monitorowaÄ‡ sytuacjÄ™. Regulator uznaje, Å¼e ryzyko jest wiÄ™ksze niÅ¼ sÄ…dzimy, wiÄ™c nakÅ‚ada "karÄ™" = zwiÄ™ksza wspÃ³Å‚czynnik k. Oznacza to, Å¼e musimy zamroziÄ‡ wiÄ™cej gotÃ³wki w rezerwach na pokrycie potencjalnych strat.

 - **Strefa Czerwona (10 i wiÄ™cej wyjÄ…tkÃ³w):** sytuacja jest zÅ‚a. Oznacza, Å¼e model wymaga poprawienia.

```{r}
# przygotowuje dane testowe
# wybieram ostatnie 250 obserwacji z mojego modelu
okno_testowe <- tail(df_model, 250)
n_test <- nrow(okno_testowe)
alpha <- 0.01 # poziom ufnoÅ›ci 99%

# zliczam wyjÄ…tki (przekroczenia)
# bÄ™dÄ™ sprawdzaÄ‡ ile razy model siÄ™ pomyliÅ‚
# wyjÄ…tek bÄ™dzie wtedy, gdy rzeczywista strata na gieÅ‚dzie jest wiÄ™ksza 
# niÅ¼ przewidywaÅ‚ model VaR.

# dla metody prostej:
# sprawdzam czy w danym dniu strata (LogReturn) byÅ‚a wiÄ™ksza niÅ¼ VaR dla metody prostej
# jeÅ›li tak = 1 (wyjÄ…tek).
# JeÅ›li nie = wpisz 0 (model zadziaÅ‚aÅ‚ poprawnie)
hits_prosta <- ifelse(okno_testowe$LogReturn < okno_testowe$VaR_Prosta_99, 1, 0)

# sumuje wszystkie wyjÄ…tki (1) by wiedzieÄ‡ ile bÅ‚Ä™dÃ³w byÅ‚o Å‚Ä…cznie w ciÄ…gu 250 dni
liczba_hits_prosta <- sum(hits_prosta)

# dla metody z wagami:
# robie to samo co dla metody prostej
# sprawdzam czy w danym dniu strata byÅ‚a wiÄ™ksza niÅ¼ VaR dla metody z wagami
hits_wagi <- ifelse(okno_testowe$LogReturn < okno_testowe$VaR_Wagi_99, 1, 0)

# sumuje wyjÄ…tki dla metody waÅ¼onej
liczba_hits_wagi <- sum(hits_wagi)
```


## Analiza iloÅ›ciowa wyjÄ…tkÃ³w (tzw. test wartoÅ›ci rzeczywistych):

```{r}
# obliczam procentowy udziaÅ‚ wyjÄ…tkÃ³w
proc_prosta <- (liczba_hits_prosta / n_test) * 100
proc_wagi <- (liczba_hits_wagi / n_test) * 100

# tabela
analiza_ilosciowa <- data.frame(
  Metoda = c("Prosta Historyczna", "Historyczna z Wagami"),
  Liczba_Wyjatkow = c(liczba_hits_prosta, liczba_hits_wagi),
  Proc_Wyjatkow = c(paste(round(proc_prosta, 2), "%"), 
                       paste(round(proc_wagi, 2), "%"))
)

kable(analiza_ilosciowa, caption = "Analiza iloÅ›ciowa wyjÄ…tkÃ³w (tzw. test wartoÅ›ci rzeczywistych)")
```

**Wyniki z Analizy iloÅ›ciowej wyjÄ…tkÃ³w (tzw. test wartoÅ›ci rzeczywistych):**

Celem modelu (dla alpha=99%) jest osiÄ…gniÄ™cie liczby wyjÄ…tkÃ³w jak najbliÅ¼szej 1%. W moim badaniu (dla 250 dni) dobrze byÅ‚oby okoÅ‚o 2-3 wyjÄ…tkÃ³w.

 - *Metoda Prosta Historyczna (1.6%):* 4 wyjÄ…tki. Wynik jest bardzo bliski celowi. Model doÅ›Ä‡ dobrze szacuje ryzyko i nie jest ani przesadnie ostroÅ¼ny, ani zbyt ryzykowny.

 - *Metoda Historyczna z Wagami (2.4%):* 6 wyjÄ…tkÃ³w. Wynik ten jest ponad 2 razy wyÅ¼szy od oczekiwanego poziomu 1%. Czyli w rzeczywistoÅ›ci straty zdarzaÅ‚y siÄ™ znacznie czÄ™Å›ciej, niÅ¼ mÃ³j model przewidywaÅ‚. Model byÅ‚ zbyt optymistyczny.

**Wniosek:** WstÄ™pna analiza iloÅ›ciowa wskazaÅ‚a mi na przewagÄ™ Metody Prostej, ktÃ³ra znacznie lepiej trzyma siÄ™ zaÅ‚oÅ¼onego poziomu 1% bÅ‚Ä™dÃ³w.


## Wyniki analizy z PodejÅ›cia regulacyjnego dla testowania wstecznego (tzw. test Å›wiateÅ‚)

```{r}
# obliczam oczekiwanÄ… liczbÄ™ wyjÄ…tkÃ³w (dla 1% z 250 dni powinno to byÄ‡ 2.5)
oczekiwane <- n_test * alpha

# funkcja do okreÅ›lania kolorÃ³w strefy
oznacz_strefe <- function(liczba_wyjatkow) {
  if (liczba_wyjatkow <= 4) {
    return("zielony")
  } else if (liczba_wyjatkow <= 9) {
    return("Å¼Ã³Å‚ty")
  } else {
    return("czerwony")
  }
}

# funkcja ustalajÄ…ca wspÃ³Å‚czynnik k
oznacz_k <- function(liczba_wyjatkow) {
  if (liczba_wyjatkow <= 4) {
    return(3.00)  # brak kary
  } else if (liczba_wyjatkow == 5) {
    return(3.40)
  } else if (liczba_wyjatkow == 6) {
    return(3.50)
  } else if (liczba_wyjatkow == 7) {
    return(3.65)
  } else if (liczba_wyjatkow == 8) {
    return(3.75)
  } else if (liczba_wyjatkow == 9) {
    return(3.85)
  } else {
    return(4.00)
  }
}

# funkcja obliczajÄ…ca prawdopodobieÅ„stwo skumulowane
# liczÄ™ to z rozkÅ‚adu dwumianowego dla okna 250 dni i VaR 99%
oznacz_prawdopodobienstwo <- function(liczba_wyjatkow) {
  
  # uÅ¼ywam funkcji pbinom (rozkÅ‚ad dwumianowy)
  # wpisujÄ™ mu 3 dane:
  # q = liczba_wyjatkow 
  # size = 250 (bo testuje ostanie 250 dni)
  # prob = 0.01 (VaR 99%, wiÄ™c szansa na bÅ‚Ä…d to 1% = 0.01)
  p_val <- pbinom(q = liczba_wyjatkow, size = 250, prob = 0.01)
  
  return(format(round(p_val, 4), nsmall = 4))
}

# tabela z wynikami
wyniki_liczbowe <- data.frame(
  Metoda = c("Prosta Historyczna", "Historyczna z Wagami"),
  Liczba_Dni = c(n_test, n_test),
  Wyjatki = c(liczba_hits_prosta, liczba_hits_wagi),
  Strefa = c(oznacz_strefe(liczba_hits_prosta), 
             oznacz_strefe(liczba_hits_wagi)),
  Wspolczynnik_k = c(oznacz_k(liczba_hits_prosta), 
                     oznacz_k(liczba_hits_wagi)),
  Cum_Prob = c(oznacz_prawdopodobienstwo(liczba_hits_prosta),
                         oznacz_prawdopodobienstwo(liczba_hits_wagi))
)

# tabela
kable(wyniki_liczbowe, caption = "Test Å›wiateÅ‚ (Strefa, Kara k, PrawdopodobieÅ„stwo)")
```


**Wyniki z tabeli:**

1. **Metoda Prosta Historyczna (zielony):** traktuje wszystkie dni z historii tak samo waÅ¼nie. DziÄ™ki temu dÅ‚ugo pamiÄ™ta stare krachy/spadki i nie bagatelizuje ryzyka. W moim przypadku model okazaÅ‚ siÄ™ wiarygodny. MieÅ›ci siÄ™ w normie (do 4 wyjÄ…tkÃ³w), wiÄ™c regulator uznaje go za bezpieczny.

2. **Metoda Historyczna z Wagami (Å¼Ã³Å‚ty):** ta metoda patrzy gÅ‚Ã³wnie na to, co dziaÅ‚o siÄ™ ostatnio. Gdy na rynku panowaÅ‚ spokÃ³j, model zbyt szybko obniÅ¼yÅ‚ prognozowane ryzyko (byÅ‚ zbyt optymistyczny). Gdy nastÄ…piÅ‚o pogorszenie, bariera zostaÅ‚a Å‚atwo przebita (6 wyjÄ…tkÃ³w u mnie). Model jest wiÄ™c niedoszacowany, co skutkuje naÅ‚oÅ¼eniem kary regulacyjnej (wspÃ³Å‚czynnik k).

**Wniosek:** W moim badaniu Metoda Prosta okazaÅ‚a siÄ™ lepsza. Mimo Å¼e reaguje wolniej na zmiany, zapewniÅ‚a nam wiÄ™kszy margines bezpieczeÅ„stwa. Metoda z wagami zbyt optymistycznie oceniÅ‚a rynek.



## Testy: Kupca i Christoffersona

PrzyjmujÄ™ poziom istotnoÅ›ci Î±=0.05.

 - p-value > 0.05: brak podstaw do odrzucenia H0â€‹. Model jest dobrze wyznaczony, wyjÄ…tki nie wystÄ™pujÄ… seriami.

 - p-value < 0.05: odrzucam H0â€‹. Model jest bÅ‚Ä™dny lub wystÄ™puje zjawisko klastrowania/grupowania.

```{r}
# testy dla metody prostej
test_prosta <- VaRTest(alpha = 0.01, 
                       actual = okno_testowe$LogReturn, 
                       VaR = okno_testowe$VaR_Prosta_99, 
                       conf.level = 0.95)

# testy dla metody z wagami
test_wagi <- VaRTest(alpha = 0.01, 
                     actual = okno_testowe$LogReturn, 
                     VaR = okno_testowe$VaR_Wagi_99, 
                     conf.level = 0.95)

# tabela
tabela_testow <- data.frame(
  Metoda = c("Prosta Historyczna", "Historyczna z Wagami"),
  
  # test Kupca
  P_Val_Kupiec = c(test_prosta$uc.LRp, test_wagi$uc.LRp),
  
  # test Christoffersena
  P_Val_Christoffersen = c(test_prosta$cc.LRp, test_wagi$cc.LRp)
)

kable(tabela_testow, digits = 4, caption = "Wyniki testÃ³w (p-value)")
```


**Wyniki z tabeli Wyniki testÃ³w (p-value)**:

1. **Metoda Prosta Historyczna:**

 - *Test Kupca (p-value 0.3805 > 0.05):* brak podstaw do odrzucenia H0â€‹. Nie ma podstaw, by twierdziÄ‡, Å¼e model jest bÅ‚Ä™dny.

 - *Test Christoffersena (p-value 0.6377 > 0.05):* brak podstaw do odrzucenia H0â€‹. Przekroczenia VaR sÄ… niezaleÅ¼ne w czasie. Nie wystÄ™puje zjawisko klastrowania/grupowania, co oznacza, Å¼e model jest stabilny.

2. **Metoda Historyczna z Wagami:**

 - *Test Kupca (p-value 0.0594 > 0.05):* brak podstaw do odrzucenia H0â€‹, ale mÃ³j wynik jest na granicy bÅ‚Ä™du. Wskazuje na to, Å¼e liczba wyjÄ…tkÃ³w jest niebezpiecznie wysoka, choÄ‡ jeszcze mieÅ›ci siÄ™ w normie statystycznej.
 
 - *Test Christoffersena (p-value 0.1458 > 0.05):* brak podstaw do odrzucenia H0â€‹. Przekroczenia VaR sÄ… niezaleÅ¼ne w czasie. Nie wystÄ™puje zjawisko klastrowania/grupowania, co oznacza, Å¼e model jest stabilny.

**Wniosek:** Obie metody sÄ… akceptowalne (w Å¼adnej byÅ‚ brak podstaw do odrzucenia H0â€‹). Jednak Metoda z Wagami jest na granicy odrzucenia, co razem z karÄ… regulacyjnÄ…/wspoÅ‚czynnikiem k (k=3.50) czyni jÄ… w badanym okresie znacznie gorszym wyborem niÅ¼ Metoda Prosta.



## Wizualizacja weryfikacji

Na poniÅ¼szym wykresie przedstawiam zgodnie z wymogami projektu (dla dÅ‚ugoÅ›ci m = 250) walidacje moich modeli na prÃ³bie testowej obejmujÄ…cej ostatnie 250 dni sesyjnych. Czerwone punkty oznaczajÄ… dni, w ktÃ³rych model zawiÃ³dÅ‚ (rzeczywista strata przebiÅ‚a barierÄ™ VaR).

```{r}
# sprawdzam czy rzeczywista strata (LogReturn) przebiÅ‚a "barierÄ™ bezpieczeÅ„stwa" (VaR)
# jeÅ›li mÃ³j model zawiÃ³dÅ‚: X
# jeÅ›li mÃ³j model zadziaÅ‚aÅ‚: NA
okno_testowe$Hit_Point_Prosta <- ifelse(okno_testowe$LogReturn < okno_testowe$VaR_Prosta_99, okno_testowe$LogReturn, NA)
okno_testowe$Hit_Point_Wagi <- ifelse(okno_testowe$LogReturn < okno_testowe$VaR_Wagi_99, okno_testowe$LogReturn, NA)

ggplot(okno_testowe, aes(x = Data)) +
  # sÅ‚upki stÃ³p zwrotu moich danych wig20
  geom_bar(aes(y = LogReturn), stat = "identity", fill = "gray90", color = "gray80") +
  
  # linie VaR
  geom_line(aes(y = VaR_Prosta_99, color = "VaR Prosty"), size = 0.8) +
  geom_line(aes(y = VaR_Wagi_99, color = "VaR z Wagami"), size = 0.8) +
  
  # punkty przekroczeÅ„ (wyjÄ…tki)
  geom_point(aes(y = Hit_Point_Prosta), color = "red", shape = 8, size = 3, stroke = 1.5) +
  geom_point(aes(y = Hit_Point_Wagi), color = "blue", shape = 4, size = 3, stroke = 1.5) +
  
  scale_color_manual(values = c("VaR Prosty" = "red", "VaR z Wagami" = "blue")) +
  
  # daty co 1 miesiÄ…c i format r-m
  scale_x_date(date_breaks = "1 month", date_labels = "%Y-%m") +
  
  labs(title = "Weryfikacja modeli (Ostatnie 250 dni)",
       y = "Zwrot/Dzienna zmiana ceny na gieÅ‚dzie [%]", x = "Data") +
       
  theme_minimal() +
  # obrÃ³t napisÃ³w Å¼eby siÄ™ zmieÅ›ciÅ‚y
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 45, hjust = 1))
```

**Wyniki wykresu:**

 - **VaR z metody prostej** widaÄ‡ powyÅ¼ej Å¼e jest bardziej stabilny. Metoda ta traktuje wszystkie obserwacje jednakowo, przez co dÅ‚uÅ¼ej pamiÄ™ta historyczne krachy i silne spadki. DziÄ™ki temu model jest bardziej ostroÅ¼ny i zostawia sobie duÅ¼y "zapas bezpieczeÅ„stwa" (czyli zakÅ‚ada gorszy scenariusz, nawet gdy na rynku jest spokojnie). Na wykresie widoczne teÅ¼ jest, Å¼e VaR prosty byÅ‚ przekraczany rzadziej (ma mniejszÄ… liczbÄ™ wyjÄ…tkÃ³w).

 - **VaR z metody z wagami** reaguje szybciej i bardziej dynamicznie na bieÅ¼Ä…cÄ… sytuacjÄ™ na rynku. WidaÄ‡ Å¼e w okresie czasu gdzie zmiennoÅ›Ä‡ byÅ‚a mniejsza, linia VaR przesuwa siÄ™ bliÅ¼ej 0, co oznacza, Å¼e model uznaÅ‚ sytuacjÄ™ za bezpiecznÄ… i przestaÅ‚ spodziewaÄ‡ siÄ™ duÅ¼ych strat. Przez to model nie byÅ‚ przygotowany na nagÅ‚e zmiany cen. WiÄ™c gdy rynek gwaÅ‚townie spadÅ‚, bariera VaR zostaÅ‚a Å‚atwo przebita, co skutkowaÅ‚o wiÄ™kszÄ… liczbÄ… bÅ‚Ä™dÃ³w dla tej metody (wyjÄ…tkÃ³w).

Moje wyniki sugerujÄ…, Å¼e model Metody z Wagami w kilku przypadkach zaniÅ¼yÅ‚ rzeczywiste ryzyko, podczas gdy model Metody Prostej skuteczniej chroniÅ‚ przed nieoczekiwanymi stratami. WiÄ™c na podstawie wykresu mogÄ™ stwierdziÄ‡, Å¼e **Prosta Metoda Historyczna** zapewnia bardziej ostroÅ¼ne i stabilne oszacowanie ryzyka VaR. **Metoda Historyczna z Wagami** mimo szybszej reakcji na zmiany na rynku, okazaÅ‚a siÄ™ zbyt "optymistyczna", co doprowadziÅ‚o jÄ… do wiÄ™kszej liczby przekroczeÅ„/wyjÄ…tkÃ³w. Czyli w moim analizowanym okresie **VaR Prosty lepiej speÅ‚nia kryteria wiarygodnoÅ›ci w testach wstecznych**.



# Ocena koÅ„cowa i wnioski

## PorÃ³wnanie skutecznoÅ›ci metod

W moim projekcie przetestowaÅ‚am dwie metody szacowania ryzyka na danych indeksu `WIG20`. Wyniki testÃ³w wstecznych (dla ostatnich 250 dni) daÅ‚y mi nastÄ™pujÄ…ce wyniki:

1.  **Prosta Metoda Historyczna:**

ZanotowaÅ‚a *4 wyjÄ…tki (1.6%)* i trafiÅ‚a do *strefy zielonej*. Test Kupca potwierdziÅ‚ poprawnÄ… liczbÄ™ przekroczeÅ„/model nie jest bÅ‚Ä™dny, a Test Christoffersena wykazaÅ‚ brak klastrowania bÅ‚Ä™dÃ³w (niezaleÅ¼noÅ›Ä‡).

2.  **Metoda Historyczna z Wagami (Zbyt ryzykowna):**

ZanotowaÅ‚a *6 wyjÄ…tkÃ³w (2.4%)*, trafiajÄ…c do *strefy Å¼Ã³Å‚tej*. Test Kupca wyszedÅ‚ na granicy odrzucenia ($p \approx 0.06$), co statystycznie potwierdza niedoszacowanie ryzyka. Jedyny plus to zaliczony Test Christoffersena (bÅ‚Ä™dy nie wystÄ™powaÅ‚y seriami). Model zbyt optymistycznie zareagowaÅ‚ na okres spokoju przed spadkami, drastycznie zaniÅ¼ajÄ…c VaR, przez co nie byÅ‚ przygotowany na nagÅ‚Ä… zmiennoÅ›Ä‡ rynku.

## Odpowiedzi na pytania badawcze

W oparciu o wyniki testÃ³w wstecznych (dla dÅ‚ugoÅ›ci m = 250), odpowiem na pytania:

1. **Czy wyznaczony VaR jest wyznaczony wiarygodnie (tj. nie jest zawyÅ¼ony ani zaniÅ¼ony)?**

Dla Prostej Metody Historycznej: **TAK.** Model jest w strefie zielonej i speÅ‚nia wszystkie wymogi statystyczne.

Dla Metody Historycznej z Wagami: **NIE (jest zaniÅ¼ony).** Model trafiÅ‚ do strefy Å¼Ã³Å‚tej i zbyt czÄ™sto dopuszczaÅ‚ do strat przekraczajÄ…cych prognozy.

2. **Czy moje wyniki pozwalajÄ… twierdziÄ‡, Å¼e obie metody dajÄ… wiarygodne oszacowania?**

**NIE.** W analizowanym okresie dla indeksu WIG20 tylko **Prosta Metoda Historyczna** okazaÅ‚a siÄ™ w wiarygodna. Metoda z Wagami, mimo szybszej reakcji na zmiany, w warunkach rzeczywistych okazaÅ‚a siÄ™ zbyt ryzykowna i wymagaÅ‚aby korekty modelu.

